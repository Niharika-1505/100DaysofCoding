{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100DaysofCoding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Day 71**\n",
        "\n",
        "**Advanced - Data Exploration with pandas: College Major vs Your Salary**"
      ],
      "metadata": {
        "id": "4izdzK19ZyH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# df=pd.read_csv(\"salaries_by_college_major.csv\")\n",
        "# print(f\"1. Head prints first 5 rows in the dataframe\\n\\n {df.head()}\\n\")\n",
        "# print(f\"2. Shape prints number of rows and columns in the dataframe{df.shape}\\n\")\n",
        "# print(f\"3. Column names: {df.columns}\\n\")\n",
        "# print(f\"4. Are there any missing values in the dataframe:\\n {df.isna()}\\n\")\n",
        "# print(f\"5. Tail prints last 5 rows of the dataframe:\\n {df.tail()}\\n\")\n",
        "# clean_df=df.dropna()\n",
        "# print(f\"6. Last 5 rows after dropping rows with NaN in the dataframe:\\n {clean_df.tail()}\\n\")\n",
        "# print(f\"7. To access one column data in the dataframe:\\n {clean_df['Starting Median Salary']}\")\n",
        "# print(f\"8. Prints maximum value in that column: {clean_df['Starting Median Salary'].max()}\\n\")\n",
        "# print(f\"9. Prints index of the maximum value in that column: {clean_df['Starting Median Salary'].idxmax()}\\n\")\n",
        "# print(f\"10. Prints cell value of a specific column and row: {clean_df['Undergraduate Major'].loc[43]}\\n\")\n",
        "# print(f\"11. Prints cell value of a specific column and row: {clean_df['Undergraduate Major'][43]}\\n\")\n",
        "# print(f\"12. Prints entire row data:\\n\\n{clean_df.loc[43]}\\n\")\n",
        "\n",
        "'''What college major has the highest mid-career salary? How much do graduates with this major earn?'''\n",
        "# College_Major_With_Highest_Mid_Career_Salary=clean_df['Undergraduate Major'].loc[clean_df['Mid-Career Median Salary'].idxmax()]\n",
        "# print(f\"13. What college major has the highest mid-career salary? {College_Major_With_Highest_Mid_Career_Salary}\")\n",
        "\n",
        "'''Which college major has the lowest starting salary and how much do graduates earn after university?'''\n",
        "# print(clean_df)\n",
        "# College_Major_With_Lowest_Starting_Salary=clean_df['Undergraduate Major'][clean_df['Starting Median Salary'].idxmin()]\n",
        "# print(f\"14. Which college major has the lowest starting salary? {College_Major_With_Lowest_Starting_Salary}\")\n",
        "\n",
        "'''Which college major has the lowest mid-career salary and how much can people expect to earn with this degree?'''\n",
        "# College_Major_With_Lowest_Mid_Career_Salary=clean_df.loc[clean_df['Mid-Career Median Salary'].idxmin()]\n",
        "# print(f\"15. What college major has the lowest mid-career salary?\\n {College_Major_With_Lowest_Mid_Career_Salary}\")\n",
        "\n",
        "# print(f\"16. Prints all the rows that meets the condition:\\n\\n {clean_df.loc[clean_df['Mid-Career 10th Percentile Salary'] >= 26000]}\")\n",
        "\n",
        "'''17. Lowest Risk Majors\n",
        "A low-risk major is a degree where there is a small difference between the lowest and highest salaries. In other words, if the difference between the \n",
        "10th percentile and the 90th percentile earnings of your major is small, then you can be more certain about your salary after you graduate.'''\n",
        "# difference_in_salaries=clean_df['Mid-Career 90th Percentile Salary'] - clean_df['Mid-Career 10th Percentile Salary']\n",
        "'''OR can use subtract method '''# clean_df['Mid-Career 90th Percentile Salary'].subtract(clean_df['Mid-Career 10th Percentile Salary'])\n",
        "# clean_df.insert(5,'difference_in_salaries',difference_in_salaries)\n",
        "# low_difference_in_salaries=clean_df.sort_values('difference_in_salaries')\n",
        "# low_difference_in_salaries[['Undergraduate Major', 'difference_in_salaries']].head()\n",
        "\n",
        "\n",
        "'''18. Find the top 5 degrees with the highest values in the 90th percentile. OR Majors with the Highest Potential'''\n",
        "# top_5_degrees=clean_df.sort_values(\"Mid-Career 90th Percentile Salary\", ascending=False)\n",
        "# top_5_degrees[['Undergraduate Major', 'Mid-Career 90th Percentile Salary']].head()\n",
        "\n",
        "'''19. Find the degrees with the greatest spread in salaries. Which majors have the largest difference between high and low earners after graduation. OR \n",
        "Majors with the Greatest Spread in Salaries'''\n",
        "# difference_in_salaries=clean_df['Mid-Career 90th Percentile Salary'].subtract(clean_df['Mid-Career 10th Percentile Salary'])\n",
        "# clean_df.insert(5,'difference_in_salaries',difference_in_salaries)\n",
        "# high_difference_in_salaries=clean_df.sort_values('difference_in_salaries', ascending=False)\n",
        "# high_difference_in_salaries[['Undergraduate Major', 'difference_in_salaries']].head()\n",
        "\n",
        "'''20.Grouping and Pivoting Data with Pandas'''\n",
        "# print(f\"20. Groups By based on columns specified and returns count:\\n\\n{clean_df.groupby('Group').count()}\\n\")\n",
        "# print(f\"21. Groups By based on columns specified and returns sum:\\n\\n{clean_df.groupby('Group').sum()}\\n\")\n",
        "# pd.options.display.float_format = '{:,.2f}'.format #Tells the pandas to round off float values to 2 decimals.\n",
        "# print(f\"22. Groups By based on columns specified and returns mean:\\n\\n{clean_df.groupby('Group').mean()}\\n\")\n",
        "\n",
        "'''23. Extra Credit - webscraping payscale website for payscale dataset '''\n",
        "\n",
        "#Reading page1 table content\n",
        "# Page_url = \"https://www.payscale.com/college-salary-report/majors-that-pay-you-back/bachelors\"\n",
        "# table = pd.read_html(Page_url)\n",
        "# payscale_df = table[0].copy()\n",
        "# payscale_df.columns = [\"Rank\", \"Major\", \"Degree Type\", \"Early Career Pay\", \"Mid-Career Pay\", \"% High Meaning\"]\n",
        "#Reading through the table contents from page2 until the end \n",
        "# for page_number in range(2, 35):\n",
        "#     table = pd.read_html(f\"{Page_url}/page/{page_number}\")\n",
        "#     page_df = table[0].copy()\n",
        "#     page_df.columns = [\"Rank\", \"Major\", \"Degree Type\", \"Early Career Pay\", \"Mid-Career Pay\", \"% High Meaning\"]\n",
        "#     payscale_df = payscale_df.append(page_df, ignore_index=True)\n",
        "\n",
        "# print(f\"24. Prints count, No. of unique rows, Top, frequency\\n\\n{payscale_df.describe()}\")\n",
        "\n",
        "#Cleaning the data\n",
        "# payscale_df[\"Rank\"] = payscale_df[\"Rank\"].str.replace(\"Rank:\", \"\")\n",
        "# payscale_df[\"Major\"] = payscale_df[\"Major\"].str.replace(\"Major:\", \"\")\n",
        "# payscale_df[\"Degree Type\"] = payscale_df[\"Degree Type\"].str.replace(\"Degree Type:\", \"\")\n",
        "# # so $ gets treated as a character\n",
        "# payscale_df[\"Early Career Pay\"] = payscale_df[\"Early Career Pay\"].str.replace(\"Early Career Pay:$\", \"\", regex=False)\n",
        "# payscale_df[\"Early Career Pay\"] = payscale_df[\"Early Career Pay\"].str.replace(\",\", \"\")\n",
        "# payscale_df[\"Mid-Career Pay\"] = payscale_df[\"Mid-Career Pay\"].str.replace(\"Mid-Career Pay:$\", \"\", regex=False)\n",
        "# payscale_df[\"Mid-Career Pay\"] = payscale_df[\"Mid-Career Pay\"].str.replace(\",\", \"\")\n",
        "# payscale_df[\"% High Meaning\"] = payscale_df[\"% High Meaning\"].str.replace(\"% High Meaning:\", \"\")\n",
        "# payscale_df[\"% High Meaning\"] = payscale_df[\"% High Meaning\"].str.replace(\"%\", \"\")\n",
        "\n",
        "# print(f\"25. Prints types of each column in the dataframe:\\n{payscale_df.dtypes}\")\n",
        "\n",
        "#Converting the data types\n",
        "# payscale_df[\"Rank\"] = payscale_df[\"Rank\"].astype(int)\n",
        "# payscale_df[\"Early Career Pay\"] = payscale_df[\"Early Career Pay\"].astype(int)\n",
        "# payscale_df[\"Mid-Career Pay\"] = payscale_df[\"Mid-Career Pay\"].astype(int)\n",
        "\n",
        "#Dataframe to csv\n",
        "# payscale_df.to_csv(\"salaries_by_college_major_29072022.csv\", index=False)\n",
        "\n",
        "data = [\n",
        "    [ 0, [\"a\",\"b\",\"c\"], [1,2,3], 7 ],\n",
        "    [ 1, [\"c\",\"d\",\"e\"], [4,5,6], 7 ],\n",
        "    [ 2, [\"f\",\"g\",\"h\"], [7,8,9], 7 ],\n",
        "    [ 3, [\"i\",\"j\",\"k\"], [10,11,12], 7],\n",
        "    [ 4, [\"l\",\"m\",\"n\"], [13,14,15], 7]\n",
        "]\n",
        "\n",
        "df = pd.DataFrame( data, columns=['one', 'two','three','four'] )\n",
        "df2 = df.explode('two')\n",
        "print(f\"26. Exploded datframe:\\n\\n {df2}\")\n"
      ],
      "metadata": {
        "id": "8uGk7NSVaH8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Day 72**\n",
        "**Advanced - Data Visualization with Matplotlib: Programming Languages**"
      ],
      "metadata": {
        "id": "2EjzwVK-KzN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"QueryResults.csv\", header=0, names=[\"DATE\", \"TAG\", \"POSTS\"])\n",
        "\n",
        "'''Challenge: Look at the first and last 5 rows of the DataFrame.'''\n",
        "print(f\"First 5 rows:\\n{df.head()}\\n\\nLast 5 rows:\\n{df.tail()}\\n\")\n",
        "\n",
        "'''Challenge: Check how many rows and how many columns there are. What are the dimensions of the dataframe?'''\n",
        "print(f\"No. of columns and rows: {df.shape}\\n\")\n",
        "\n",
        "'''Challenge: Count the number of entries in each column of the dataframe'''\n",
        "print(f\"Count of number of entries in each column:\\n{df.count()}\\n\")\n",
        "\n",
        "'''Challenge: Calculate the total number of post per language. Which Programming language has had the highest total number of posts of all time?'''\n",
        "total_post_per_lang_df = df.groupby('TAG').sum()\n",
        "pl_with_more_posts = total_post_per_lang_df['POSTS'].idxmax()\n",
        "print(f\"Total no. of posts per language:\\n{total_post_per_lang_df}\\n\\nand {pl_with_more_posts} is the programming language with more posts\\n\")\n",
        "\n",
        "'''Challenge: How many months of data exist per language? Which language had the fewest months with an entry?'''\n",
        "total_months_of_data_per_lang = df.groupby('TAG').count()\n",
        "pl_with_few_months_entry = total_months_of_data_per_lang['POSTS'].idxmin()\n",
        "print(f\"No. of months of data per language:\\n{total_months_of_data_per_lang}\\n\\nand {pl_with_few_months_entry} is the programming language with few months of entry\\n\")\n",
        "\n",
        "'''Data Cleaning'''\n",
        "\n",
        "'''Change Date format to datetime object'''\n",
        "print(f\"Type of the Date: {type(df['DATE'][1])}\")\n",
        "pd.to_datetime(df[\"DATE\"][1]) #This will change the datatype to datetime but also print the date in this 2022-07-01 00:00:00\n",
        "df[\"DATE\"] = pd.to_datetime(df[\"DATE\"]) #This will change the datatype to datetime but print the date in this 2022-07-01\n",
        "print(f\"Changing date format from str to datetime:\\n\\n{df['DATE']}\\n\")\n",
        "\n",
        "'''Data Manipulation'''\n",
        "\n",
        "reshaped_df = df.pivot(index='DATE', columns='TAG', values='POSTS')\n",
        "'''Challenge: What are the dimensions of our new dataframe? How many rows and columns does it have?'''\n",
        "print(f\"No. of columns and rows in reshaped: {reshaped_df.shape}\\nFirst 5 rows:\\n{reshaped_df.head()}\\n\\nLast 5 rows:\\n{reshaped_df.tail()}\\n\\nPrints column names:{reshaped_df.columns}\\n\")\n",
        "print(f\"Count of number of entries in each column:\\n{reshaped_df.count()}\\n\")\n",
        "\n",
        "# replace NaN values\n",
        "reshaped_df.fillna(0, inplace=True)\n",
        "# confirm that there are no NaN values\n",
        "print(f\"Are there any Nan values: {reshaped_df.isna().values.any()}\")\n",
        "\n",
        "reshaped_df"
      ],
      "metadata": {
        "id": "4QM3sJHlLHzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visualisaton with with Matplotlib**"
      ],
      "metadata": {
        "id": "OIrgwbqzlV1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''Challenge: Use the matplotlib documentation to plot a single programming language (e.g., java) on a chart.'''\n",
        "\n",
        "#change the size of the graph\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "#Increase x and y axis labels size\n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "\n",
        "#Add label names to x and y axis\n",
        "plt.xlabel(\"Year\", fontsize=13)\n",
        "plt.ylabel(\"Posts\", fontsize=13)\n",
        "\n",
        "#Plot the data on the graph\n",
        "plt.plot(reshaped_df.index, reshaped_df[\"python\"])\n",
        "\n",
        "'''Challenge: Show two line (e.g. for Java and Python) on the same chart.'''\n",
        "plt.figure(figsize=(10,6)) \n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.xlabel(\"Year\", fontsize=13)\n",
        "plt.ylabel(\"Posts\", fontsize=13)\n",
        "\n",
        "# Changing y-axis limit from 30000 to 40000\n",
        "plt.ylim(0, 40000)\n",
        "\n",
        "plt.plot(reshaped_df.index, reshaped_df[\"python\"])\n",
        "plt.plot(reshaped_df.index, reshaped_df[\"java\"])\n",
        "\n",
        "'''Challenge: Multi-line charts with matplotlib'''\n",
        "plt.figure(figsize=(10,6)) \n",
        "plt.xticks(fontsize=13)\n",
        "plt.yticks(fontsize=13)\n",
        "plt.xlabel(\"Year\", fontsize=13)\n",
        "plt.ylabel(\"Posts\", fontsize=13)\n",
        "plt.ylim(0, 40000)\n",
        "\n",
        "#Loops through the dataframe columns and plot all the columns on the graph and add \n",
        "for column in reshaped_df.columns:\n",
        "    plt.plot(reshaped_df.index, reshaped_df[column], \n",
        "             linewidth=3, label=reshaped_df[column].name)\n",
        "\n",
        "# include a legend\n",
        "# loc=2 means \"upper left\"\n",
        "plt.legend(fontsize=12, loc=2)\n"
      ],
      "metadata": {
        "id": "ewXjFE1aldQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Smoothing out Time-Series Data**\n",
        "\n",
        "Looking at our last chart above we see that time-series data can be quite noisy, with a lot of up and down spikes. This can sometimes make it difficult to see what's going on.\n",
        "\n",
        "A useful technique to make a trend apparent is to smooth out the observations by taking an average. By averaging say, 6 or 12 observations we can construct something called the rolling mean. Essentially we calculate the average in a window of time and move it forward by one observation at a time."
      ],
      "metadata": {
        "id": "Exl-WIVqtjWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# smooth out the data using rolling mean\n",
        "# The window is number of observations that are averaged here is 6\n",
        "roll_df = reshaped_df.rolling(window=6).mean()\n",
        " \n",
        "plt.figure(figsize=(10,6))\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Number of Posts', fontsize=14)\n",
        "plt.ylim(0, 35000)\n",
        " \n",
        "# plot the roll_df instead\n",
        "for column in roll_df.columns:\n",
        "    plt.plot(roll_df.index, roll_df[column], \n",
        "             linewidth=3, label=roll_df[column].name)\n",
        " \n",
        "plt.legend(fontsize=16)"
      ],
      "metadata": {
        "id": "JuIELCTVtk7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using a smaller window\n",
        "# The window is number of observations that are averaged here is 3\n",
        "roll_df = reshaped_df.rolling(window=3).mean()\n",
        " \n",
        "plt.figure(figsize=(10,6))\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Number of Posts', fontsize=14)\n",
        "plt.ylim(0, 35000)\n",
        " \n",
        "# plot the roll_df instead\n",
        "for column in roll_df.columns:\n",
        "    plt.plot(roll_df.index, roll_df[column], \n",
        "             linewidth=3, label=roll_df[column].name)\n",
        " \n",
        "plt.legend(fontsize=16)"
      ],
      "metadata": {
        "id": "k-cieddWy8fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using a larger window\n",
        "# The window is number of observations that are averaged here is 12\n",
        "roll_df = reshaped_df.rolling(window=12).mean()\n",
        " \n",
        "plt.figure(figsize=(10,6))\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Number of Posts', fontsize=14)\n",
        "plt.ylim(0, 35000)\n",
        " \n",
        "# plot the roll_df instead\n",
        "for column in roll_df.columns:\n",
        "    plt.plot(roll_df.index, roll_df[column], \n",
        "             linewidth=3, label=roll_df[column].name)\n",
        " \n",
        "plt.legend(fontsize=16)"
      ],
      "metadata": {
        "id": "Q2DE0Pvoy9Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Day 73**\n",
        "**Advanced - Aggregate & Merge Data with Pandas: Analyse the LEGO Dataset**\n",
        "\n",
        "# Introduction\n",
        "\n",
        "Today we'll dive deep into a dataset all about LEGO. From the dataset we can ask whole bunch of interesting questions about the history of the LEGO company, their product offering, and which LEGO set ultimately rules them all:\n",
        "\n",
        "<ul type=\"square\">\n",
        "<li>What is the most enormous LEGO set ever created and how many parts did it have?</li>\n",
        "\n",
        "<li>How did the LEGO company start out? In which year were the first LEGO sets released and how many sets did the company sell when it first launched?</li>\n",
        "\n",
        "<li>Which LEGO theme has the most sets? Is it one of LEGO's own themes like Ninjago or a theme they licensed liked Harry Potter or Marvel Superheroes?</li>\n",
        "\n",
        "<li>When did the LEGO company really expand its product offering? Can we spot a change in the company strategy based on how many themes and sets did it released year-on-year?</li>\n",
        "\n",
        "<li>Did LEGO sets grow in size and complexity over time? Do older LEGO \n",
        "sets tend to have more or fewer parts than newer sets?</li>\n",
        "</ul>\n",
        "\n",
        "\n",
        "**Data Source**\n",
        "\n",
        "[Rebrickable](https://rebrickable.com/downloads/) has compiled data on all the LEGO pieces in existence. I recommend you use download the .csv files provided in this lesson. "
      ],
      "metadata": {
        "id": "I_epgg-f_0-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zM64pr7nAQab"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}